{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7205fbc5-f3fe-4175-8f35-b32b8bac8bf5",
   "metadata": {},
   "source": [
    "| ü¶æ **Level 1: Neural Network Foundations** | \n",
    "\n",
    "‚úîÔ∏è Manual model building <br> ‚úîÔ∏è Activation functions <br> ‚úîÔ∏è Loss functions <br> ‚úîÔ∏è Optimizers & gradients |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65766cfb-df40-4f8f-93cb-357332cc5e27",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Manual Model Building (Linear Regression Example)\n",
    "\n",
    "In PyTorch, you can manually define:\n",
    "- **Weights** (parameters)\n",
    "- **Forward pass** (the function that predicts outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be07189d-53bb-4f8e-bf4b-cc01e1cab246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tensor([[1.6230],\n",
      "        [1.5230],\n",
      "        [0.6219],\n",
      "        [0.5890],\n",
      "        [0.6048]], grad_fn=<AddBackward0>)\n",
      "Real value:  tensor([[-3.7075],\n",
      "        [-3.2084],\n",
      "        [ 1.2877],\n",
      "        [ 1.4521],\n",
      "        [ 1.3730]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample data: 5 inputs, 1 output\n",
    "X = torch.randn(5, 1)\n",
    "y_true = 3 * X + 1  # The true relationship\n",
    "\n",
    "# Initialize weight and bias (parameters)\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Forward pass: prediction\n",
    "y_pred = w * X + b\n",
    "print(\"Prediction: \",y_pred)\n",
    "print(\"Real value: \",y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e42d7-62d8-4e73-aa78-674f249df42a",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Activation Functions\n",
    "- Activation functions add non-linearity to neural networks. Common ones include:\n",
    "    - ReLU (Rectified Linear Unit)\n",
    "    - Sigmoid\n",
    "    - Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0b1fef-ae6a-4be1-9589-85590793b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# ReLU\n",
    "relu_output = F.relu(y_pred)\n",
    "\n",
    "# Sigmoid\n",
    "sigmoid_output = torch.sigmoid(y_pred)\n",
    "\n",
    "# Tanh\n",
    "tanh_output = torch.tanh(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980d0cb-e64c-4a49-8241-32aead05a289",
   "metadata": {},
   "source": [
    "‚úÖ In manual models, activations are inserted after linear computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb06cf5-aca7-4be2-bb50-31247e82de89",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Loss Functions\n",
    "- A loss function measures the difference between the model‚Äôs predictions and the true values.\n",
    "Common losses:\n",
    "\n",
    "    - MSE (Mean Squared Error) ‚Äî for regression\n",
    "    - Cross-Entropy ‚Äî for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fb476b-378e-41ef-81bf-a7e99271e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5158, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# MSE Loss (regression example)\n",
    "loss = torch.mean((y_pred - y_true) ** 2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a8cc4d-edb9-4b4e-91c5-b539f26b0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "loss = loss_fn(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8a5430-b78e-42b0-b6b6-63041f7187e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5158, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11552c12-09cc-4d79-a56d-0e9d78998bbe",
   "metadata": {},
   "source": [
    "## ‚úîÔ∏è Optimizers & Gradients\n",
    "- To train the model:\n",
    "    - Compute the loss.\n",
    "    - Use .backward() to compute gradients.\n",
    "    - Update weights with an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "403814d8-bde6-49e5-bd29-0ba725c2defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Update parameters\n",
    "optimizer.step()\n",
    "\n",
    "# Zero gradients for next iteration\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda9189-a4cd-4432-937a-140479f8dc68",
   "metadata": {},
   "source": [
    "‚úÖ This loop is the core of training any neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b2bcc17-cf45-4260-94de-e3b3b1d78c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8988b7-abb3-4d58-bf5d-89eabf071f78",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary Table\n",
    "\n",
    "| Concept               | PyTorch Example                                           |\n",
    "|-----------------------|----------------------------------------------------------|\n",
    "| Manual Model          | `y_pred = w * X + b`                                      |\n",
    "| Activation Functions  | `F.relu()`, `torch.sigmoid()`, `torch.tanh()`             |\n",
    "| Loss Functions        | `torch.nn.MSELoss()`, manual `(y_pred - y_true) ** 2`     |\n",
    "| Optimizer + Gradients | `optimizer.step()`, `loss.backward()`                     |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-macos)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
