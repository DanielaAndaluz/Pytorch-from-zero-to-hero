{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb604015-2dd0-46d8-9eaa-c84015dc4544",
   "metadata": {},
   "source": [
    "## ü•ö Zero: The Basics\n",
    "\n",
    "This is the **starting point** for learning PyTorch. Before building neural networks, it's essential to understand the **foundational concepts** that everything else is built on.\n",
    "\n",
    "### ‚úîÔ∏è What is PyTorch?\n",
    "- **PyTorch** is an open-source **machine learning** and **deep learning** framework developed by **Meta (Facebook)**.\n",
    "- It's widely used in both **research and industry** because it is:\n",
    "  - **Easy to learn**\n",
    "  - **Highly flexible**\n",
    "  - **Powerful for building complex models** such as those used in computer vision, NLP, and generative AI.\n",
    "\n",
    "### ‚úîÔ∏è Installing PyTorch\n",
    "- You can install PyTorch easily using `pip` or `conda`, with or without GPU support (CUDA).\n",
    "- Example installation:\n",
    "  ```bash\n",
    "  pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc731b5-f527-401a-9e7f-c42dc302be81",
   "metadata": {},
   "source": [
    "### ‚úîÔ∏è Tensors & Operations\n",
    "- Tensors are the core data structure in PyTorch, similar to NumPy arrays, but with the added benefit of automatic differentiation and GPU acceleration.\n",
    "- You can perform basic operations such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ddef38-9910-47b6-884f-bb02863fd6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "z = x + y  # Tensor addition\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502504f-3de0-4701-b537-c939f7b39800",
   "metadata": {},
   "source": [
    "Tensors support:\n",
    "\n",
    "- Math operations\n",
    "\n",
    "- Broadcasting\n",
    "\n",
    "- Reshaping and slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fbf96-3de4-4f3f-8c88-6db5d9c670ee",
   "metadata": {},
   "source": [
    "### ‚úîÔ∏è Autograd Basics\n",
    "\n",
    "- Autograd is PyTorch's automatic differentiation engine.\n",
    "- It allows PyTorch to automatically compute gradients needed for training neural networks.\n",
    "- Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d9300b-0a5e-4244-bbbd-05d16ad1c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 3\n",
    "y.backward()\n",
    "print(x.grad)  # Prints the derivative dy/dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d316c5-5477-4d5d-a9a0-a48703081a83",
   "metadata": {},
   "source": [
    "- This is the foundation for backpropagation in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f2a1863-dba2-4b71-aaa4-e273c872dd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([5., 7., 9.])\n",
      "Element-wise Multiplication: tensor([ 4., 10., 18.])\n",
      "Dot Product: tensor(32.)\n",
      "Tensor on device: tensor([1., 2., 3.], device='mps:0')\n",
      "Value of a: 2.0\n",
      "Gradient db/da: 12.0\n",
      "\n",
      "Summary:\n",
      "- PyTorch tensors behave like NumPy arrays but support GPU and autograd.\n",
      "- Autograd automatically computes gradients for backpropagation.\n"
     ]
    }
   ],
   "source": [
    "# ü¶æ PyTorch: From Zero to Hero ‚Äî Zero: The Basics\n",
    "\n",
    "# Install PyTorch (Uncomment if running locally)\n",
    "# !pip install torch torchvision torchaudio\n",
    "\n",
    "import torch\n",
    "\n",
    "# 3Ô∏è‚É£ Tensors & Operations\n",
    "\n",
    "# Create Tensors\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# Basic Operations\n",
    "z = x + y\n",
    "m = x * y\n",
    "\n",
    "dot_product = torch.dot(x, y)\n",
    "\n",
    "print(\"Addition:\", z)\n",
    "print(\"Element-wise Multiplication:\", m)\n",
    "print(\"Dot Product:\", dot_product)\n",
    "\n",
    "# Moving tensors to GPU if available\n",
    "device = torch.device(\"mps\")  # Apple's Metal Performance Shaders\n",
    "x_gpu = x.to(device)\n",
    "print(\"Tensor on device:\", x_gpu)\n",
    "\n",
    "# ---\n",
    "# 4Ô∏è‚É£ Autograd Basics\n",
    "\n",
    "# Create tensor with gradient tracking\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Define function\n",
    "b = a ** 3  # b = a^3\n",
    "\n",
    "# Backward pass\n",
    "b.backward()\n",
    "\n",
    "print(\"Value of a:\", a.item())\n",
    "print(\"Gradient db/da:\", a.grad.item())\n",
    "\n",
    "# ---\n",
    "# 5Ô∏è‚É£ Summary\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"- PyTorch tensors behave like NumPy arrays but support GPU and autograd.\")\n",
    "print(\"- Autograd automatically computes gradients for backpropagation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-macos)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
