{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26eb7950-320d-40f6-b1d2-27a4ac62c273",
   "metadata": {},
   "source": [
    "# ⚡ Level 5: Transfer Learning & Pre-trained Models\n",
    "\n",
    "In this level, you'll learn how to use **pre-trained models** to save time, compute, and data—by leveraging models trained on massive datasets like **ImageNet** or **large language corpora**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✔️ Fine-tuning vs Feature Extraction\n",
    "\n",
    "| Strategy            | What It Means                                               | When to Use                                           |\n",
    "|---------------------|------------------------------------------------------------|------------------------------------------------------|\n",
    "| **Feature Extraction** | Freeze pre-trained layers, only train new classifier layers. | When you have **small datasets** or need speed.       |\n",
    "| **Fine-Tuning**       | Unfreeze part or all of the model and **train everything**. | When you have **more data** or need high accuracy.    |\n",
    "\n",
    "✅ You can mix both: freeze early layers, fine-tune later ones.\n",
    "\n",
    "---\n",
    "\n",
    "## ✔️ Using Pretrained Models for Vision (`torchvision`)\n",
    "\n",
    "PyTorch makes it easy to load popular pre-trained models for **image classification**, **object detection**, etc.\n",
    "\n",
    "### Example: ResNet Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd92353-5b70-45cc-bd4c-3be5b8b59f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Use the new weights API\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# Load pre-trained ResNet18 with default weights\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier head (example: binary classification)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a74ffb-3806-4550-920e-5048abf6fcd1",
   "metadata": {},
   "source": [
    "✅ You can now train only the new classifier layer while using the powerful pre-trained features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526ddef-ed06-46d5-bb56-76318770edd3",
   "metadata": {},
   "source": [
    "## ✔️ Using Pretrained Models for NLP (transformers)\n",
    "- For Natural Language Processing (NLP), use the transformers library \n",
    "\n",
    "Example: Sentiment Classification with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b7231bb-cb6a-41ea-b585-9f6719b00a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5340299606323242\n",
      "Logits: tensor([[ 0.1685,  0.3404],\n",
      "        [ 0.2842, -0.2611]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import Adam\n",
    "\n",
    "# ✔️ Load tokenizer and pre-trained BERT model for classification\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# ✔️ Sample texts and binary labels (1 = positive, 0 = negative)\n",
    "texts = [\"I love this movie!\", \"This was the worst experience ever.\"]\n",
    "labels = torch.tensor([1, 0])  # Ground truth\n",
    "\n",
    "# ✔️ Tokenize the texts\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# ✔️ Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "labels = labels.to(device)\n",
    "\n",
    "# ✔️ Set up optimizer\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "# ✔️ Training loop (one epoch example)\n",
    "model.train()\n",
    "outputs = model(**inputs, labels=labels)\n",
    "\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Loss:\", loss.item())\n",
    "print(\"Logits:\", logits)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876121e-562c-4c90-a53e-e967c985c729",
   "metadata": {},
   "source": [
    "✅ This works for tasks like sentiment analysis, question answering, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a40aca-f448-48e2-87ee-3cc215c28118",
   "metadata": {},
   "source": [
    "## ✅ Summary Table\n",
    "\n",
    "| Concept                  | PyTorch Example                                                        |\n",
    "|--------------------------|-------------------------------------------------------------------------|\n",
    "| Feature Extraction        | Freeze layers: `param.requires_grad = False`                           |\n",
    "| Fine-Tuning               | Unfreeze layers: `param.requires_grad = True`                          |\n",
    "| Pre-trained Vision Models | `torchvision.models.resnet18(pretrained=True)`                         |\n",
    "| Pre-trained NLP Models    | `transformers.BertForSequenceClassification.from_pretrained()`         |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-macos)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
